env: "MountainCarMilestones-v0"
num_milestones: 10
milestone_reward: 0.5
policy: "MlpPolicy"
learning_rate: 0.003
gradient_steps: 64
batch_size: 32
buffer_size: 600000

plot:
  enabled: True
  update_interval: 10000
  reset_heat_map_every_update: True
  # Configure smoothing per plot
  smooth:
    # Set to True to enable plot smoothing in general
    enabled: True
    # If a plot is not mentioned it will default to False
    # See plot_results() in AdaptiveDQN.py
    milestones: True
    episode_rewards: True
    total_rewards: True
    n: 11
log:
  enabled: True
  save_interval: 20000
policy_kwargs:
  net_arch: [ 64,64 ]
uncertainty_kwargs:
  scale: 0.1
  state_bounds: null
  resolution: 15
  first_n_dim: 2
visualize_environment_only: false # If true then don't train but render the environment given the setup
eps_zero: 1.00
eps_min: 0.08
denominator: 500 # For methods adaptive3 and adaptive4
decay_rate: 1.5e-6
demosteps: 1000
trainsteps: 800000
eval_rate: 10000 # Evaluate after every eval_rate timesteps
seed: 123
exploration_method: "traditional_milestones" # See ExplorationMethod enum for all methods
exploration_fraction: 0.1